{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haobin_11_22\n",
      "kevin_11_7\n",
      "russell_11_7\n",
      "kelly_11_7\n",
      "russell_11_20_stand\n"
     ]
    }
   ],
   "source": [
    "xs, ys = data_loader.verified_subjects_calibrated_yprs(resampled=True, flatten=True)\n",
    "xs = np.array(xs)\n",
    "ys = np.array(ys)\n",
    "trainx, testx, trainy, testy = train_test_split(xs, ys, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['haobin_11_22', 'kevin_11_7', 'russell_11_7', 'kelly_11_7'],\n",
       " ['russell_11_20_stand'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subjects = data_loader.VERIFIED_SUBJECTS[:-1]\n",
    "test_subjects = data_loader.VERIFIED_SUBJECTS[-1:]\n",
    "train_subjects , test_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haobin_11_22\n",
      "kevin_11_7\n",
      "russell_11_7\n",
      "kelly_11_7\n",
      "russell_11_20_stand\n"
     ]
    }
   ],
   "source": [
    "trainx, trainy = data_loader.verified_subjects_calibrated_yprs(resampled=True, flatten=True, subjects=train_subjects)\n",
    "testx, testy = data_loader.verified_subjects_calibrated_yprs(resampled=True, flatten=True, subjects=test_subjects)\n",
    "trainx = np.array(trainx)\n",
    "trainy = np.array(trainy)\n",
    "testx = np.array(testx)\n",
    "testy = np.array(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2090, 300), (2090,), (520, 300), (520,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.shape, trainy.shape, testx.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(pred, testy):\n",
    "    correct_pred = (pred-testy == 0).astype(int)\n",
    "    acc = np.sum(correct_pred) / pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svc with linear kernel\n",
      "Training svc with poly kernel\n",
      "Training svc with rbf kernel\n",
      "Training svc with sigmoid kernel\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "svc_acc = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(f'Training svc with {kernel} kernel')\n",
    "    clf = svm.SVC(kernel=kernel, gamma='auto')\n",
    "    clf.fit(trainx, trainy)\n",
    "    pred = clf.predict(testx)\n",
    "    svc_acc[kernel] = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': 0.2403846153846154,\n",
       " 'poly': 0.25576923076923075,\n",
       " 'rbf': 0.038461538461538464,\n",
       " 'sigmoid': 0.038461538461538464}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KNN with n=2\n",
      "Running KNN with n=3\n",
      "Running KNN with n=4\n",
      "Running KNN with n=5\n",
      "Running KNN with n=6\n",
      "Running KNN with n=7\n",
      "Running KNN with n=8\n",
      "Running KNN with n=9\n",
      "Running KNN with n=10\n",
      "Running KNN with n=11\n",
      "Running KNN with n=12\n",
      "Running KNN with n=13\n",
      "Running KNN with n=14\n"
     ]
    }
   ],
   "source": [
    "knn_acc = {}\n",
    "\n",
    "for num_neighbor in range(2, 15):\n",
    "    print(f'Running KNN with n={num_neighbor}')\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=num_neighbor)\n",
    "    clf.fit(trainx, trainy)\n",
    "    \n",
    "    pred = clf.predict(testx)\n",
    "    knn_acc[num_neighbor] = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0.2423076923076923,\n",
       " 3: 0.24423076923076922,\n",
       " 4: 0.24423076923076922,\n",
       " 5: 0.2230769230769231,\n",
       " 6: 0.2173076923076923,\n",
       " 7: 0.2153846153846154,\n",
       " 8: 0.21346153846153845,\n",
       " 9: 0.21923076923076923,\n",
       " 10: 0.2173076923076923,\n",
       " 11: 0.19615384615384615,\n",
       " 12: 0.19807692307692307,\n",
       " 13: 0.2,\n",
       " 14: 0.19423076923076923}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = NearestCentroid()\n",
    "clf.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05471698113207547"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(testx)\n",
    "correct_pred = (pred-testy == 0).astype(int)\n",
    "acc = np.sum(correct_pred) / pred.shape[0]\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso: linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1, max_iter=5000)\n",
    "clf.fit(trainx, trainy)\n",
    "pred = clf.predict(testx)\n",
    "pred = np.rint(pred)\n",
    "acc = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04905660377358491"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(trainx, trainy)\n",
    "pred = clf.predict(testx)\n",
    "acc = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04339622641509434"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest of randomized trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junshenchen/anaconda3/envs/cs229proj-mac/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(trainx, trainy)\n",
    "pred = clf.predict(testx)\n",
    "acc = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09433962264150944"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic NN (multi-layer perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = [\n",
    "    (100,50),\n",
    "    (100,100,50),\n",
    "    (200,50),\n",
    "    (200,100,50),\n",
    "]\n",
    "\n",
    "activations = ['logistic', 'tanh', 'relu']\n",
    "\n",
    "l2_reg_const = [0.0001 * x for x in [1, 5, 10]]\n",
    "\n",
    "nn_acc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn-(100, 50)-logistic-0.0001\n",
      "nn-(100, 50)-logistic-0.0005\n",
      "nn-(100, 50)-logistic-0.001\n",
      "nn-(100, 50)-tanh-0.0001\n",
      "nn-(100, 50)-tanh-0.0005\n",
      "nn-(100, 50)-tanh-0.001\n",
      "nn-(100, 50)-relu-0.0001\n",
      "nn-(100, 50)-relu-0.0005\n",
      "nn-(100, 50)-relu-0.001\n",
      "nn-(100, 100, 50)-logistic-0.0001\n",
      "nn-(100, 100, 50)-logistic-0.0005\n",
      "nn-(100, 100, 50)-logistic-0.001\n",
      "nn-(100, 100, 50)-tanh-0.0001\n",
      "nn-(100, 100, 50)-tanh-0.0005\n",
      "nn-(100, 100, 50)-tanh-0.001\n",
      "nn-(100, 100, 50)-relu-0.0001\n",
      "nn-(100, 100, 50)-relu-0.0005\n",
      "nn-(100, 100, 50)-relu-0.001\n",
      "nn-(200, 50)-logistic-0.0001\n",
      "nn-(200, 50)-logistic-0.0005\n",
      "nn-(200, 50)-logistic-0.001\n",
      "nn-(200, 50)-tanh-0.0001\n",
      "nn-(200, 50)-tanh-0.0005\n",
      "nn-(200, 50)-tanh-0.001\n",
      "nn-(200, 50)-relu-0.0001\n",
      "nn-(200, 50)-relu-0.0005\n",
      "nn-(200, 50)-relu-0.001\n",
      "nn-(200, 100, 50)-logistic-0.0001\n",
      "nn-(200, 100, 50)-logistic-0.0005\n",
      "nn-(200, 100, 50)-logistic-0.001\n",
      "nn-(200, 100, 50)-tanh-0.0001\n",
      "nn-(200, 100, 50)-tanh-0.0005\n",
      "nn-(200, 100, 50)-tanh-0.001\n",
      "nn-(200, 100, 50)-relu-0.0001\n",
      "nn-(200, 100, 50)-relu-0.0005\n",
      "nn-(200, 100, 50)-relu-0.001\n"
     ]
    }
   ],
   "source": [
    "for structure in structures:\n",
    "    for act in activations:\n",
    "        for alpha in l2_reg_const:\n",
    "            name = f'nn-{str(structure)}-{act}-{alpha}'\n",
    "            print(name)\n",
    "            \n",
    "            clf = MLPClassifier(\n",
    "                hidden_layer_sizes=structure,\n",
    "                activation=act,\n",
    "                alpha=alpha,\n",
    "                max_iter=5000\n",
    "            )\n",
    "            clf.fit(trainx, trainy)\n",
    "            pred = clf.predict(testx)\n",
    "            \n",
    "            nn_acc[name] = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn-(100, 50)-logistic-0.0001': 0.6800766283524904,\n",
       " 'nn-(100, 50)-logistic-0.0005': 0.6666666666666666,\n",
       " 'nn-(100, 50)-logistic-0.001': 0.6685823754789272,\n",
       " 'nn-(100, 50)-tanh-0.0001': 0.6513409961685823,\n",
       " 'nn-(100, 50)-tanh-0.0005': 0.6666666666666666,\n",
       " 'nn-(100, 50)-tanh-0.001': 0.6954022988505747,\n",
       " 'nn-(100, 50)-relu-0.0001': 0.7298850574712644,\n",
       " 'nn-(100, 50)-relu-0.0005': 0.7203065134099617,\n",
       " 'nn-(100, 50)-relu-0.001': 0.7260536398467433,\n",
       " 'nn-(100, 100, 50)-logistic-0.0001': 0.5363984674329502,\n",
       " 'nn-(100, 100, 50)-logistic-0.0005': 0.5766283524904214,\n",
       " 'nn-(100, 100, 50)-logistic-0.001': 0.5478927203065134,\n",
       " 'nn-(100, 100, 50)-tanh-0.0001': 0.6877394636015326,\n",
       " 'nn-(100, 100, 50)-tanh-0.0005': 0.6915708812260536,\n",
       " 'nn-(100, 100, 50)-tanh-0.001': 0.6800766283524904,\n",
       " 'nn-(100, 100, 50)-relu-0.0001': 0.7777777777777778,\n",
       " 'nn-(100, 100, 50)-relu-0.0005': 0.7911877394636015,\n",
       " 'nn-(100, 100, 50)-relu-0.001': 0.7509578544061303,\n",
       " 'nn-(200, 50)-logistic-0.0001': 0.7528735632183908,\n",
       " 'nn-(200, 50)-logistic-0.0005': 0.7490421455938697,\n",
       " 'nn-(200, 50)-logistic-0.001': 0.7432950191570882,\n",
       " 'nn-(200, 50)-tanh-0.0001': 0.7241379310344828,\n",
       " 'nn-(200, 50)-tanh-0.0005': 0.6877394636015326,\n",
       " 'nn-(200, 50)-tanh-0.001': 0.6839080459770115,\n",
       " 'nn-(200, 50)-relu-0.0001': 0.7796934865900383,\n",
       " 'nn-(200, 50)-relu-0.0005': 0.7337164750957854,\n",
       " 'nn-(200, 50)-relu-0.001': 0.6992337164750958,\n",
       " 'nn-(200, 100, 50)-logistic-0.0001': 0.6226053639846744,\n",
       " 'nn-(200, 100, 50)-logistic-0.0005': 0.6762452107279694,\n",
       " 'nn-(200, 100, 50)-logistic-0.001': 0.6187739463601533,\n",
       " 'nn-(200, 100, 50)-tanh-0.0001': 0.6877394636015326,\n",
       " 'nn-(200, 100, 50)-tanh-0.0005': 0.6934865900383141,\n",
       " 'nn-(200, 100, 50)-tanh-0.001': 0.7088122605363985,\n",
       " 'nn-(200, 100, 50)-relu-0.0001': 0.7873563218390804,\n",
       " 'nn-(200, 100, 50)-relu-0.0005': 0.7701149425287356,\n",
       " 'nn-(200, 100, 50)-relu-0.001': 0.7777777777777778}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
