{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Processing albert\nProcessing canon_12_5\nProcessing daniel\nProcessing haobin_11_22\nProcessing isa_12_5\nProcessing janet\nProcessing joanne\nProcessing jq_12_6\nProcessing kelly_11_7\nProcessing kevin_11_7\nProcessing ruocheng\nProcessing russell_11_20_stand\nProcessing russell_11_7\nProcessing russell_random_12_7\nProcessing solomon\nProcessing wenzhou_12_5\nProcessing yiheng_11_30\nProcessing yiheng_12_5\nProcessing yongxu_11_30\nProcessing albert\nProcessing canon_12_5\nProcessing daniel\nProcessing haobin_11_22\nProcessing isa_12_5\nProcessing janet\nProcessing joanne\nProcessing jq_12_6\nProcessing kelly_11_7\nProcessing kevin_11_7\nProcessing ruocheng\nProcessing russell_11_20_stand\nProcessing russell_11_7\nProcessing russell_random_12_7\nProcessing solomon\nProcessing wenzhou_12_5\nProcessing yiheng_11_30\nProcessing yiheng_12_5\nProcessing yongxu_11_30\nSplitting out test set\nSplitting out dev and train set\n"
    }
   ],
   "source": [
    "xs, ys = data_loader.verified_subjects_calibrated_yprs(resampled=True, flatten=True)\n",
    "xs = np.array(xs)\n",
    "ys = np.array(ys)\n",
    "trainx, devx, testx, trainy, devy, testy = data_loader.load_all_classic_random_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Augmenting TRAIN set with proportion 1\n"
    },
    {
     "data": {
      "text/plain": "((15336, 300), (959, 300), (959, 300), (15336,), (959,), (959,))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx, trainy = data_loader.augment_train_set(trainx, trainy)\n",
    "trainx.shape, devx.shape, testx.shape, trainy.shape, devy.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_subjects = data_loader.VERIFIED_SUBJECTS[:-2]\n",
    "# test_subjects = data_loader.VERIFIED_SUBJECTS[-2:]\n",
    "# train_subjects , test_subjects"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainx, trainy = data_loader.verified_subjects_calibrated_yprs(resampled=True, flatten=True, subjects=train_subjects)\n",
    "# testx, testy = data_loader.verified_subjects_calibrated_yprs(resampled=True, flatten=True, subjects=test_subjects)\n",
    "# trainx = np.array(trainx)\n",
    "# trainy = np.array(trainy)\n",
    "# testx = np.array(testx)\n",
    "# testy = np.array(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainx.shape, trainy.shape, testx.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(pred, testy):\n",
    "    correct_pred = (pred-testy == 0).astype(int)\n",
    "    acc = np.sum(correct_pred) / pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training svc with poly kernel\n"
    }
   ],
   "source": [
    "kernels = ['poly']\n",
    "svc_acc = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(f'Training svc with {kernel} kernel')\n",
    "    clf = svm.SVC(kernel=kernel, gamma='auto', max_iter=25000)\n",
    "    clf.fit(trainx, trainy)\n",
    "    pred = clf.predict(testx)\n",
    "    svc_acc[kernel] = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'poly': 0.43274244004171014}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Running KNN with n=2\nRunning KNN with n=3\nRunning KNN with n=4\nRunning KNN with n=5\nRunning KNN with n=6\nRunning KNN with n=7\nRunning KNN with n=8\nRunning KNN with n=9\n"
    }
   ],
   "source": [
    "test_acc = {}\n",
    "\n",
    "for num_neighbor in range(2, 10):\n",
    "    print(f'Running KNN with n={num_neighbor}')\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=num_neighbor)\n",
    "    clf.fit(trainx, trainy)\n",
    "    \n",
    "    pred = clf.predict(testx)\n",
    "    test_acc[num_neighbor] = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{2: 0.7382690302398331,\n 3: 0.7539103232533889,\n 4: 0.7497393117831074,\n 5: 0.7403545359749739,\n 6: 0.7299270072992701,\n 7: 0.7174139728884255,\n 8: 0.7257559958289885,\n 9: 0.7174139728884255}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NearestCentroid()\n",
    "clf.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(testx)\n",
    "correct_pred = (pred-testy == 0).astype(int)\n",
    "acc = np.sum(correct_pred) / pred.shape[0]\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lasso: linear regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1, max_iter=5000)\n",
    "clf.fit(trainx, trainy)\n",
    "pred = clf.predict(testx)\n",
    "pred = np.rint(pred)\n",
    "acc = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(trainx, trainy)\n",
    "pred = clf.predict(testx)\n",
    "acc = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forest of randomized trees"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(trainx, trainy)\n",
    "pred = clf.predict(testx)\n",
    "acc = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic NN (multi-layer perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = [\n",
    "    (100,50),\n",
    "    (100,100,50),\n",
    "    (200,50),\n",
    "    (200,100,50),\n",
    "]\n",
    "\n",
    "activations = ['logistic', 'tanh', 'relu']\n",
    "\n",
    "l2_reg_const = [0.0001 * x for x in [1, 5, 10]]\n",
    "\n",
    "nn_acc = {}"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "for structure in structures:\n",
    "    for act in activations:\n",
    "        for alpha in l2_reg_const:\n",
    "            name = f'nn-{str(structure)}-{act}-{alpha}'\n",
    "            print(name)\n",
    "            \n",
    "            clf = MLPClassifier(\n",
    "                hidden_layer_sizes=structure,\n",
    "                activation=act,\n",
    "                alpha=alpha,\n",
    "                max_iter=5000\n",
    "            )\n",
    "            clf.fit(trainx, trainy)\n",
    "            pred = clf.predict(testx)\n",
    "            \n",
    "            nn_acc[name] = get_acc(pred, testy)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_acc"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}