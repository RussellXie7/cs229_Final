{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import data_loader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing albert\n",
      "Processing canon_12_5\n",
      "Processing Chen_12_7\n",
      "Processing daniel\n",
      "Processing haobin_11_22\n",
      "Processing isa_12_5\n",
      "Processing janet\n",
      "Processing joanne\n",
      "Processing jq_12_6\n",
      "Processing kelly_11_7\n",
      "Processing kevin_11_7\n",
      "Processing ruocheng\n",
      "Processing russell_11_20_stand\n",
      "Processing russell_11_7\n",
      "Processing russell_random_12_7\n",
      "Processing solomon\n",
      "Processing wenzhou_12_5\n",
      "Processing yiheng_11_30\n",
      "Processing yiheng_12_5\n",
      "Processing yongxu_11_30\n",
      "Processing Zhaoye_12_7\n",
      "Splitting out test set\n",
      "Splitting out dev and train set\n"
     ]
    }
   ],
   "source": [
    "trainx, devx, testx, trainy, devy, testy = data_loader.load_all_classic_random_split(flatten=False)\n",
    "# trainx, devx, testx, trainy, devy, testy = data_loader.load_all_subject_split(flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting TRAIN set with proportion 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((41600, 100, 3), (1040, 100, 3), (1041, 100, 3), (41600,), (1040,), (1041,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx, trainy = data_loader.augment_train_set(trainx, trainy, augment_prop=4, is_flattened=False)\n",
    "trainx.shape, devx.shape, testx.shape, trainy.shape, devy.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "\n",
    "def get_dataloader(x, y, batch_size):\n",
    "    dataset = [(x[i].T, y[i]) for i in range(y.shape[0])]\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "trainloader = get_dataloader(trainx, trainy, BATCH_SIZE)\n",
    "devloader = get_dataloader(devx, devy, BATCH_SIZE)\n",
    "testloader = get_dataloader(testx, testy, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, num_feature, num_channel = trainx.shape\n",
    "num_feature, num_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_loss(data_loader, criterion):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            x, y = data\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "                \n",
    "            outputs = net(x.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            w = torch.sum((predicted - y) != 0).item()\n",
    "            r = len(y) - w\n",
    "            correct += r \n",
    "            total += len(y)\n",
    "            \n",
    "            total_loss += criterion(outputs, y.long()).item() * len(x)\n",
    "    return correct / total, total_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(3, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool1): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (pool2): MaxPool1d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (pool3): MaxPool1d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=6400, out_features=3200, bias=True)\n",
       "  (fc2): Linear(in_features=3200, out_features=1600, bias=True)\n",
       "  (fc3): Linear(in_features=1600, out_features=500, bias=True)\n",
       "  (out): Linear(in_features=500, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1\n",
    "        )  \n",
    "        # 16 channel, num_feature\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "        # 16 channel, num_feature\n",
    "\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2\n",
    "        )\n",
    "        # 32 channel, num_feature\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=5, stride=1, padding=2)\n",
    "        # 32 channel, num_feature\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(\n",
    "            in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(num_feature * 64, 3200)\n",
    "        self.fc2 = nn.Linear(3200, 1600)\n",
    "        self.fc3 = nn.Linear(1600, 500)\n",
    "        self.out = nn.Linear(500, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, num_feature * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "net = Net()\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 trainacc=0.37790865384615385 devacc=0.4009615384615385\n",
      "        trainloss=2.019430611282587 devloss=2.0451032037918386\n",
      "Epoch 1 trainacc=0.6906009615384615 devacc=0.6211538461538462\n",
      "        trainloss=1.0157071811935077 devloss=1.3558958081098704\n",
      "Epoch 2 trainacc=0.8387740384615384 devacc=0.6990384615384615\n",
      "        trainloss=0.5124957016311013 devloss=1.2425738985721881\n",
      "Epoch 3 trainacc=0.9067548076923077 devacc=0.7144230769230769\n",
      "        trainloss=0.29004434388704026 devloss=1.3873514670592089\n",
      "Epoch 4 trainacc=0.9458413461538462 devacc=0.7403846153846154\n",
      "        trainloss=0.17698415426107553 devloss=1.5150411472870753\n",
      "Epoch 5 trainacc=0.9634375 devacc=0.7326923076923076\n",
      "        trainloss=0.12303681940270159 devloss=1.4985613754162421\n",
      "Epoch 6 trainacc=0.971610576923077 devacc=0.7461538461538462\n",
      "        trainloss=0.09888304095679465 devloss=1.6851233198092535\n",
      "Epoch 7 trainacc=0.9806730769230769 devacc=0.7423076923076923\n",
      "        trainloss=0.06708014573758611 devloss=1.6751060073192303\n",
      "Epoch 8 trainacc=0.9810336538461538 devacc=0.7692307692307693\n",
      "        trainloss=0.07093465238666305 devloss=1.7732033316905682\n",
      "Epoch 9 trainacc=0.9824038461538461 devacc=0.7480769230769231\n",
      "        trainloss=0.061397055383377634 devloss=1.7783363048846905\n",
      "Epoch 10 trainacc=0.9880769230769231 devacc=0.7538461538461538\n",
      "        trainloss=0.04113811936426478 devloss=1.8485193367187793\n",
      "Epoch 11 trainacc=0.9879567307692307 devacc=0.75\n",
      "        trainloss=0.04213309365933618 devloss=1.8216638496288886\n",
      "Epoch 12 trainacc=0.9848076923076923 devacc=0.7615384615384615\n",
      "        trainloss=0.061047491196614616 devloss=1.9176894609744732\n",
      "Epoch 13 trainacc=0.9930288461538461 devacc=0.7663461538461539\n",
      "        trainloss=0.025240398506866768 devloss=1.760793034846966\n",
      "Epoch 14 trainacc=0.9817307692307692 devacc=0.7442307692307693\n",
      "        trainloss=0.060481940678213365 devloss=1.8930601156674898\n",
      "Epoch 15 trainacc=0.9879086538461539 devacc=0.7615384615384615\n",
      "        trainloss=0.04585148222619095 devloss=1.7851441502571106\n",
      "Epoch 16 trainacc=0.9860817307692308 devacc=0.7557692307692307\n",
      "        trainloss=0.051337307574263275 devloss=1.9000799518365126\n",
      "Epoch 17 trainacc=0.9902644230769231 devacc=0.7625\n",
      "        trainloss=0.038098065857551634 devloss=1.9017644432874827\n",
      "Epoch 18 trainacc=0.9919230769230769 devacc=0.7576923076923077\n",
      "        trainloss=0.04554424175092628 devloss=1.8879431875852437\n",
      "Epoch 19 trainacc=0.9908653846153846 devacc=0.7673076923076924\n",
      "        trainloss=0.04242974990763916 devloss=1.6581797485168164\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "optimizer = optim.AdamW(net.parameters(), weight_decay=0.1)\n",
    "\n",
    "hist = defaultdict(list)\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    trainacc, trainloss = acc_loss(trainloader, criterion)\n",
    "    devacc, devloss = acc_loss(devloader, criterion)\n",
    "    hist['trainacc'].append(trainacc)\n",
    "    hist['trainloss'].append(trainloss)\n",
    "    hist['devacc'].append(devacc)\n",
    "    hist['devloss'].append(devloss)\n",
    "    \n",
    "    print(f'Epoch {epoch} trainacc={trainacc} devacc={devacc}')\n",
    "    print(f'        trainloss={trainloss} devloss={devloss}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "testacc, testloss = acc_loss(testloader, nn.CrossEntropyLoss())\n",
    "testacc, testloss\n",
    "hist['testacc'] = testacc\n",
    "hist['testloss'] = testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cnn_hist_random.json', 'w') as f:\n",
    "    json.dump(hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
